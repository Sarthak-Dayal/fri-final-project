{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel, TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "\n",
    "from pytesseract import Output\n",
    "import pytesseract\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from scipy.ndimage import rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "text_processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "text_model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2dc0cbbfb50ada1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    return image\n",
    "\n",
    "def get_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:,:,3] = 0\n",
    "    for i in range(len(sorted_anns)):\n",
    "        ann = sorted_anns[i]\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    return img\n",
    "\n",
    "def show_annotated(annotated_image):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(annotated_image)\n",
    "    # masked_img = show_anns(masks)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "    # ax.imshow(masked_img[0:100])\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc070443d38a0c53"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def text_preprocess(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    return thresh\n",
    "\n",
    "def text_orientation_correction(image):\n",
    "    edges = cv2.Canny(image, 50, 150, apertureSize=3)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 100, minLineLength=100, maxLineGap=10)\n",
    "    angles = []\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        angle = np.degrees(np.arctan2(y2 - y1, x2 - x1))\n",
    "        angles.append(angle)\n",
    "    average_angle = np.mean(angles)\n",
    "    corrected_image = rotate(image, -average_angle)\n",
    "    return corrected_image\n",
    "\n",
    "def extract_text(image):\n",
    "    custom_config = r'--oem 3 --psm 6'\n",
    "    text = pytesseract.image_to_string(image, config=custom_config)\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f9d6cb7b1b21f25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def classify_mask_as_book(masked_img, labels=[\"book\", \"not book\"]):\n",
    "    # Apply the mask to the image\n",
    "    # masked_img = np.zeros_like(image)\n",
    "    # masked_img[mask] = image[mask]\n",
    "\n",
    "    # Prepare the image for the CLIP model\n",
    "    pil_image = Image.fromarray(masked_img)\n",
    "    inputs = processor(text=labels, images=pil_image, return_tensors=\"pt\", padding=True)\n",
    "    outputs = clip_model(**inputs)\n",
    "\n",
    "    # Get the predicted label\n",
    "    logits_per_image = outputs.logits_per_image\n",
    "    probs = torch.softmax(logits_per_image, dim=1)\n",
    "    best_label_idx = torch.argmax(probs)\n",
    "    return labels[best_label_idx] == \"book\"\n",
    "\n",
    "def extract_text_from_mask(masked_img):\n",
    "    # Apply the mask to the image\n",
    "    # masked_img = np.zeros_like(image)\n",
    "    # masked_img[mask] = image[mask]\n",
    "\n",
    "    # Extract text using pytesseract\n",
    "    text = pytesseract.image_to_string(masked_img)\n",
    "    return text.strip()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6798c310b77baa09"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image = load_image(\"original_image.jpg\")\n",
    "sam = sam_model_registry[\"vit_h\"](checkpoint=\"sam_vit_h_4b8939.pth\")\n",
    "sam.to(device=\"cpu\")\n",
    "image = cv2.resize(image, (1024, 1024), interpolation=cv2.INTER_LINEAR)\n",
    "print(1)\n",
    "\n",
    "mask_generator = SamAutomaticMaskGenerator(model=sam,\n",
    "                                           points_per_side=32,\n",
    "                                           points_per_batch=128,\n",
    "                                           pred_iou_thresh=0.98,\n",
    "                                           stability_score_thresh=0.97,\n",
    "                                           crop_n_layers=1,\n",
    "                                           crop_n_points_downscale_factor=2,\n",
    "                                           min_mask_region_area=500)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f24710267304c076"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "masks = mask_generator.generate(image)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d371e5d27f0e329b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mask_annotator = sv.MaskAnnotator(color_lookup = sv.ColorLookup.INDEX)\n",
    "detections = sv.Detections.from_sam(masks)\n",
    "annotated_image = mask_annotator.annotate(image, detections)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "174787403366521b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_annotated(annotated_image)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "958d5b96297eef69"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "book_count = 0\n",
    "count = 0\n",
    "for i, mask_dict in enumerate(masks):\n",
    "    mask = np.repeat(mask_dict['segmentation'][:, :, np.newaxis].astype(np.uint8), 3, axis=2) * 255\n",
    "    masked_img = image.copy()\n",
    "    cv2.bitwise_and(image.astype(np.uint8), mask, masked_img)\n",
    "    count += 1\n",
    "\n",
    "    if classify_mask_as_book(masked_img):\n",
    "        book_count += 1\n",
    "        title = extract_text_from_mask(masked_img)\n",
    "        print(f\"Book {book_count} title: {title}\")\n",
    "    else:\n",
    "        print(f\"Segment {count} not a book\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e53323434f87af51"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
